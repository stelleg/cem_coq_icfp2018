\section{Instruction Machine} \label{sec:mach}

In this section we describe the instruction machine syntax and semantics, and
how the relation with the stack machine from the previous section works. We can
then write down the full relation to the natural semantics of the source by
composing this relation with the big-step to small-step relation. We thus end
up with our final proof, namely that the call-by-need semantics are preserved
by the machine semantics. 

\subsection{Instruction Assembly}

Our instruction syntax is described in Section~\ref{sec:intro}. Unlike the
relation between the big step and small step semantics, the relation between
the smallstep semantics and the instruction machine semantics requires an 
assembly step. The assembler compiles lambda terms with deBruijn indices into
instructions. It is in fact the only program transformation in this compiler, 
which is a testament the ease of compilation of the $\mathcal{CE}$ machine.

We give the full assembly function in Figure~\ref{fig:assemble}. 

\begin{figure}
\begin{lstlisting}
Fixpoint var_inst (i : nat) : BasicBlock := match i with
  | 0 => push EP ;
         push (RC 0) ;
         mov (EP%0) R1 ;
         mov (EP%1) EP ;
         jump None R1
  | S i => mov EP (EP%2) ;
           var_inst i
  end.

Fixpoint assemble (t : tm) (k : nat) : Program := match t with  
  | var v => [var_inst v]
  | app m n => let ms := assemble m (k+1) in
               let nk := k + 1 + length ms in
                 push EP ;
                 push (RC nk) ;
                 jump None (RC (k+1)) :: 
                 ms ++ 
                 assemble n nk
  | lam b => pop R1 ;
             jump (Some (RW (WR R1), (k+1))) (RC (k+2)) ::
             (*Update*)
             pop R1 ;  
             mov (RC k) (R1%0) ;
             mov EP (R1%1) ;
             jump None (RC k) ::
             (*Take*)
             new 3 R2 ;
             mov R1 (R2%0);
             pop (R2%1) ;
             mov EP (R2%2) ;
             mov R2 EP ;
             jump None (k+3) ::
             assemble b (k+3)
  end. 
\end{lstlisting}
\caption{Assembler in Coq}
\end{figure}

For variables, the code compiles a basic block that follows the shared
environment pointer the appropriate number of times, followed by pushing an
update marker pointing to the closure in the heap that will be updated. For
the application, we push the argument closure onto the stack then continue
into the left hand side. This push-enter style compiler is the simplest to 
reason about, though investigating eval-apply could make for interesting future
work. Finally, abstractions are compiled into three basic blocks, the first checks
if the top of the stack is an update marker or a instruction pointer and branches
appropriately, while the second performs the update by replacing the closure 
at the update location with the current closure, and the third binds the 
argument closure to a new heap location. Note that our new location requires three
machine words: the instruction pointer, environment pointer pair that makes 
up the closure, as well as the shared environment pointer pointing to the 
environment that was extended with said closure. 

\subsection{Machine Semantics}

The machine semantics are fairly straightf given the instructions and
machine state. We omit the full semantics, though they are available in the
source Coq files.

Some of the less obvious semantics: a closure is represented as two machine
words, or \texttt{nat}s in our case. The first is an instruction pointer. The
second is an environment pointer pointing into the heap. Our current closure is
defined by our instruction pointer and environment pointer registers. 

In general, the machine semantics are fairly predictable given the instructions 
available. The \texttt{pop} instruction pops a machine word off of the stack and
into the write operand, while the \texttt{push} reads the read operand and pushes
it onto the stack. While we have implemented the stack as a list of words, it 
would be straightforward future work to lower this further to be implemented as
an in-memory array. Our \texttt{new} instruction returns an unused chunk of
memory of the given size. Note that as with the small step $\mathcal{CE}$ semantics,
in the future the semantics should be updated to be able to re-use dead memory
locations, something which we currently don't manage. 

We implement our program as a finite map from machine pointers to basic blocks. 
Because we use the null pointer as a marker for updates on the stack, we start
our basic block indices at 1. As with the stack, it would make for
straightforward future work to replace the instruction pointer so that the
instructions and basic blocks were represented in memory directly. 

On the stack, we differentiate between update markers and argument closures by
using a zero in place of an instruction pointer, therefore disallowing a zero
instruction pointer, in agreement with modern conventions. We can then check for
zero on the top of the stack using the optional first argument to our jump
instruction. If the argument operand is zero, then we jump to the given
constant location, otherwise we jump the fallback second argument. 

\subsection{Relation with Small Step $\mathcal{CE}$ Semantics}

We define our relation on the basic blocks created by the compiler. We relate
the machine and small step states in fairly simple ways. The deBruijn terms of
the small step semantics are all replaced with instruction pointers, and we
require that the mapping preserves a program equivalence. This relation relies
on the fact that each subterm corresponds with a subprogram starting at the given
instruction pointer.
 
Once we have a notion of program equivalence, we can define a notion of
environment equivalence. This is defined by induction on the environment
structure, requiring that every term reachable by that $\mathcal{CE}$
environment is equivalent to the corresponding instruction pointer in the 
instruction machine for a given program. Combined with program equivalence, we
can define a closure equivalence relation to relate the instruction machine closures
with the $\mathcal{CE}$ machine closures. Once we have that relation, we can
define a relation to relate the complete instruction machine states with the
$\mathcal{CE}$ machine state. We then show that this relation holds for the
initial states for each, and that it holds by induction on the step relation
of the $\mathcal{CE}$ machine.

\begin{figure}
\begin{lstlisting}

\end{lstlisting}
\caption{}
\end{figure}

For execution of instructions, we relate each rule in the small step semantics
to a basic block of code. Note that we've artificially increased the number of
instructions in this case and could trivially show that a sound optimization
is removing all of the unconditional \texttt{jmp} instructions to the next
basic block.  

In the same way substitution is often modeled as a single step, when
implementing the lookup in the machine semantics we must convert our
\texttt{clu} to a an inductive lookup executed by machine instructions. Of
course, this takes a number of instructions proportional to the size of the
deBruijn index. Our program equivalence relation ensures the number of steps
the \texttt{clu} lookup takes is equivalent to the number of indirections
taken by the generated code.

Our heap relation is fairly straightforward. Each cell of the $\mathcal{CE}$
semantics corresponds with three machine words: for the closure there will be an
instruction pointer and an environment pointer, and then one machine words for
the environment continuation. A cell is equivalent to one of these triplets iff
the instruction pointer points to a basic block that is equivalent to the term,
and the environment pointers are equivalent modulo heap location isomorphism.

Note that we do require that the \texttt{new} instruction returns a block of
machine words. This is in contrast to flat representations, where it needs to
return blocks of variables sizes. This is also a situation in which the
simplicity of the $\mathcal{CE}$ machine is very valuable: because of this
constant sized closures, we don't need to worry about cases in which the
value closure that we update a heap location with has more free variables, and
therefore requires more space, leading to the need for indirections as in the
STG machine \cite{STG}.


